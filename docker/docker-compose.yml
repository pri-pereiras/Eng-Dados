version: '3.8'

services:
  mysql:
    image: mysql:8.0
    environment:
      MYSQL_ROOT_PASSWORD: airflow
      MYSQL_DATABASE: airflow
      MYSQL_USER: airflow
      MYSQL_PASSWORD: airflow
    ports:
      - "3306:3306"
    networks:
      - laboratorio-airflow-tier

  postgres:
    image: postgres:13
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    ports:
      - "5432:5432"
    networks:
      - laboratorio-airflow-tier

      ############################
##  DATA LAKE
############################
  minio:
    image: minio/minio:latest
    container_name: minio
    entrypoint: sh
    command:   '-c ''mkdir -p /minio_data/raw && mkdir -p /minio_data/trusted && minio server /minio_data --console-address ":9001"'''
    ports:
      - "9050:9000"
      - "9051:9001"
    hostname: minio
    environment:
      MINIO_ROOT_USER: admin
      MINIO_ROOT_PASSWORD: minioadmin
      MINIO_ACCESS_KEY: datalake
      MINIO_SECRET_KEY: datalake
    volumes:
      - ./minio/data1:/data

  webserver:
    build: .
#    image: apache/airflow:2.7.2-python3.11
    restart: always
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      AIRFLOW__CORE__FERNET_KEY: ${FERNET_KEY}
      AIRFLOW__WEBSERVER__SECRET_KEY: '${FERNET_KEY}2'
      AIRFLOW__CORE__LOAD_EXAMPLES: 'True'
    volumes:
      - ../dags:/opt/airflow/dags
      - ../requirements.txt:/requirements.txt
      - C:\Users\pri_p\OneDrive\FIA\PÃ³s - Engenharia de Dados\03 - Engenharia de Dados\Projeto Final\Eng_Dados\airflow\data:/opt/airflow/data
    ports:
      - "8080:8080"
    depends_on:
      - postgres
    networks:
      - laboratorio-airflow-tier
    command: >
      bash -c "pip install -r /requirements.txt && airflow db init && airflow webserver"

  scheduler:
    build: .
#    image: apache/airflow:2.7.2-python3.11
    restart: always
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      AIRFLOW__CORE__FERNET_KEY: ${FERNET_KEY}
      AIRFLOW__WEBSERVER__SECRET_KEY: '${FERNET_KEY}2'
    volumes:
      - ../dags:/opt/airflow/dags
      - ../requirements.txt:/requirements.txt
      - ${AIRFLOW_PROJ_DIR:-.}/data:/opt/airflow/data
    depends_on:
      - postgres
    networks:
      - laboratorio-airflow-tier
    command: >
      bash -c "pip install -r /requirements.txt && airflow scheduler"

networks:
  laboratorio-airflow-tier:
    driver: bridge

